# ğŸ“Š Pasta Data - Datasets Locais

## ğŸ¯ PropÃ³sito
Esta pasta Ã© destinada ao armazenamento de datasets locais utilizados no projeto IBM Data Analyst Professional Certificate Capstone. Aqui vocÃª encontrarÃ¡ todos os arquivos de dados necessÃ¡rios para executar anÃ¡lises, criar visualizaÃ§Ãµes e gerar relatÃ³rios.

## ğŸ“ Estrutura de Arquivos

### Tipos de Datasets Suportados
- **CSV Files** (`.csv`): Dados tabulares principais
- **Excel Files** (`.xlsx`, `.xls`): Planilhas com mÃºltiplas abas
- **JSON Files** (`.json`): Dados estruturados em formato JSON
- **SQL Files** (`.sql`): Scripts de consulta e criaÃ§Ã£o de dados

### OrganizaÃ§Ã£o Recomendada
```
data/
â”œâ”€â”€ raw/                    # Dados brutos originais
â”‚   â”œâ”€â”€ sales_data.csv      # Dados de vendas
â”‚   â”œâ”€â”€ customer_data.xlsx  # InformaÃ§Ãµes de clientes  
â”‚   â””â”€â”€ products.json       # CatÃ¡logo de produtos
â”œâ”€â”€ processed/              # Dados processados/limpos
â”‚   â”œâ”€â”€ clean_sales.csv     # Vendas apÃ³s limpeza
â”‚   â””â”€â”€ aggregated_data.csv # Dados agregados
â”œâ”€â”€ external/               # Dados de fontes externas
â”‚   â”œâ”€â”€ market_data.csv     # Dados de mercado
â”‚   â””â”€â”€ economic_indicators.json
â””â”€â”€ samples/                # Datasets de exemplo/teste
    â”œâ”€â”€ sample_sales.csv    # Amostra para desenvolvimento
    â””â”€â”€ test_data.json      # Dados para testes
```

## ğŸ” Datasets Principais

### 1. Sales Data (sales_data.csv)
- **DescriÃ§Ã£o**: Dados histÃ³ricos de vendas da empresa
- **Colunas**: date, product_id, customer_id, quantity, unit_price, total_amount, region
- **PerÃ­odo**: Janeiro 2023 - Atual
- **Uso**: AnÃ¡lise de performance de vendas, trends e forecasting

### 2. Customer Data (customer_data.xlsx)
- **DescriÃ§Ã£o**: InformaÃ§Ãµes completas dos clientes
- **Abas**: 
  - `customers`: Dados pessoais e demogrÃ¡ficos
  - `segments`: SegmentaÃ§Ã£o de clientes
  - `interactions`: HistÃ³rico de interaÃ§Ãµes
- **Uso**: Customer analytics, segmentaÃ§Ã£o, anÃ¡lise de churn

### 3. Product Catalog (products.json)
- **DescriÃ§Ã£o**: CatÃ¡logo completo de produtos
- **Estrutura**: ID, nome, categoria, preÃ§o, custo, margem
- **Uso**: AnÃ¡lise de rentabilidade, performance por produto

### 4. Market Data (market_data.csv)
- **DescriÃ§Ã£o**: Dados externos de mercado e competidores
- **Fonte**: APIs externas e relatÃ³rios de mercado
- **Uso**: AnÃ¡lise competitiva, benchmarking

## ğŸ“ˆ Como Usar os Datasets

### 1. Carregamento em Python
```python
import pandas as pd
import json

# Carregar CSV
sales_df = pd.read_csv('data/raw/sales_data.csv')

# Carregar Excel (mÃºltiplas abas)
customer_sheets = pd.read_excel('data/raw/customer_data.xlsx', sheet_name=None)
customers_df = customer_sheets['customers']

# Carregar JSON
with open('data/raw/products.json', 'r') as f:
    products_data = json.load(f)
```

### 2. Carregamento em SQL
```sql
-- Importar CSV para PostgreSQL
COPY sales_data FROM 'data/raw/sales_data.csv' 
WITH (FORMAT CSV, HEADER TRUE);

-- Criar tabela temporÃ¡ria
CREATE TEMP TABLE temp_sales AS 
SELECT * FROM sales_data WHERE date >= '2024-01-01';
```

### 3. Carregamento no Excel
- Use **Data > Get Data > From File** para importar CSVs
- Para dados JSON, use **Power Query** para transformaÃ§Ã£o
- Configure **Power Pivot** para anÃ¡lises avanÃ§adas

## ğŸ› ï¸ Ferramentas de AnÃ¡lise

### Python Libraries
- **pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **numpy**: OperaÃ§Ãµes numÃ©ricas
- **matplotlib/seaborn**: VisualizaÃ§Ãµes
- **plotly**: GrÃ¡ficos interativos
- **scikit-learn**: Machine learning

### SQL Tools
- **PostgreSQL**: Banco principal
- **DBeaver**: Interface grÃ¡fica
- **pgAdmin**: AdministraÃ§Ã£o PostgreSQL

### BI Tools
- **Tableau**: VisualizaÃ§Ãµes profissionais
- **Power BI**: Dashboards corporativos
- **Excel**: AnÃ¡lises rÃ¡pidas e pivot tables

## ğŸ“‹ Qualidade dos Dados

### ValidaÃ§Ãµes Implementadas
- âœ… VerificaÃ§Ã£o de valores nulos
- âœ… ValidaÃ§Ã£o de tipos de dados
- âœ… Checks de integridade referencial
- âœ… DetecÃ§Ã£o de outliers
- âœ… ValidaÃ§Ã£o de formatos de data

### Scripts de Limpeza
```python
# Exemplo de limpeza bÃ¡sica
from src.utils.data_quality import DataQualityChecker

checker = DataQualityChecker()
quality_report = checker.validate_dataset(
    data=sales_df,
    rules=['no_nulls', 'valid_dates', 'positive_amounts']
)
```

## ğŸ”„ ETL Process

### ExtraÃ§Ã£o (Extract)
- APIs externas para dados de mercado
- ExportaÃ§Ãµes de CRM/ERP
- Web scraping (quando autorizado)

### TransformaÃ§Ã£o (Transform)
- Limpeza e padronizaÃ§Ã£o
- CÃ¡lculo de mÃ©tricas derivadas
- AgregaÃ§Ãµes e sumarizaÃ§Ãµes
- Joins entre diferentes fontes

### Carregamento (Load)
- PostgreSQL para dados estruturados
- Data warehouse para anÃ¡lises histÃ³ricas
- Cache em CSV/Parquet para performance

## ğŸ“Š KPIs e MÃ©tricas Calculadas

### MÃ©tricas de Vendas
- **Revenue Growth**: Taxa de crescimento de receita
- **Average Order Value (AOV)**: Valor mÃ©dio do pedido
- **Units per Transaction**: Unidades por transaÃ§Ã£o

### MÃ©tricas de Cliente
- **Customer Acquisition Cost (CAC)**: Custo de aquisiÃ§Ã£o
- **Customer Lifetime Value (CLV)**: Valor do ciclo de vida
- **Churn Rate**: Taxa de cancelamento

### MÃ©tricas Operacionais
- **Inventory Turnover**: Giro de estoque
- **Profit Margin**: Margem de lucro por produto
- **Regional Performance**: Performance por regiÃ£o

## ğŸ”’ SeguranÃ§a e Privacidade

### Dados SensÃ­veis
- âš ï¸ **Nunca commitar** dados reais de clientes
- ğŸ” Use **dados anonimizados** para desenvolvimento
- ğŸ“ **GDPR Compliance**: Remover PII quando necessÃ¡rio

### Backup e Versionamento
- ğŸ’¾ **Backup diÃ¡rio** dos dados crÃ­ticos
- ğŸ“Š **Versionamento** de datasets importantes
- ğŸ”„ **HistÃ³rico** de transformaÃ§Ãµes aplicadas

## ğŸš€ Getting Started

1. **Clone o repositÃ³rio**
2. **Instale as dependÃªncias**: `pip install -r requirements.txt`
3. **Configure as conexÃµes** de banco em `config/database.py`
4. **Execute a validaÃ§Ã£o** dos dados: `python src/utils/data_quality.py`
5. **Inicie a anÃ¡lise** com os notebooks em `notebooks/`

## ğŸ“ Suporte

Para questÃµes sobre os datasets ou processo de anÃ¡lise:
- ğŸ“§ **Email**: gabrieldemetrios@gmail.com
- ğŸ› **Issues**: Use o GitHub Issues para reportar problemas
- ğŸ“– **DocumentaÃ§Ã£o**: Veja `/docs` para guias detalhados

---
*Ãšltima atualizaÃ§Ã£o: Setembro 2025*
*VersÃ£o: 1.0.0*
